services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: "2000"
    ports: ["2181:2181"]
    networks: [lake]

  kafka:
    image: confluentinc/cp-kafka:7.6.1
    depends_on: [zookeeper]
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"   # lets producer auto-create trips_raw
    ports: ["9092:9092"]
    networks: [lake]


  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=minio
      - MINIO_ROOT_PASSWORD=minio12345
    ports: ["9000:9000", "9001:9001"]
    volumes:
      - minio-data:/data
    networks: [lake]

  postgres:
    image: postgres:14
    environment:
      - POSTGRES_USER=metastore
      - POSTGRES_PASSWORD=metastore
      - POSTGRES_DB=metastore
    ports: ["5432:5432"]
    volumes:
      - pg-data:/var/lib/postgresql/data
    networks: [lake]

  hive-metastore:
    build: ./hive
    depends_on: [postgres, minio]
    command: ["bash","-lc","/opt/hive/bin/hive --service metastore -p 9083"]
    environment:
      - HIVE_CONF_DIR=/opt/hive/conf
    ports: ["9083:9083"]
    volumes:
      - ./hive/conf/hive-site.xml:/opt/hive/conf/hive-site.xml:ro
    networks: [lake]


  trino:
    image: trinodb/trino:440
    depends_on: [hive-metastore, minio]
    ports: ["8082:8080"]
    volumes:
      - ./trino/etc/catalog:/etc/trino/catalog
    networks: [lake]

  airflow-webserver:
    image: apache/airflow:2.9.2
    depends_on: [postgres]
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__WEBSERVER__SECRET_KEY=supersecret
      - _PIP_ADDITIONAL_REQUIREMENTS=great_expectations==0.18.14
    user: "50000:0"
    command: bash -lc "airflow db init && airflow users create --username airflow --password airflow --firstname a --lastname b --role Admin --email a@b.c || true && airflow webserver"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/great_expectations:/opt/airflow/great_expectations
      - airflow-logs:/opt/airflow/logs
    ports: ["8080:8080"]
    networks: [lake]

  airflow-scheduler:
    image: apache/airflow:2.9.2
    depends_on: [airflow-webserver]
    user: "50000:0"
    command: bash -lc "airflow scheduler"
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/great_expectations:/opt/airflow/great_expectations
      - airflow-logs:/opt/airflow/logs
    networks: [lake]

  spark-submit:
    image: apache/spark:3.5.1
    depends_on: [kafka, minio, hive-metastore]
    environment:
      AWS_ACCESS_KEY_ID: minio
      AWS_SECRET_ACCESS_KEY: minio12345
      AWS_REGION: us-east-1
      S3_ENDPOINT: http://minio:9000
      SPARK_MODE: client
    volumes:
      - ./spark/scala/target:/jobs
      # Optional: mount extra jars if you need s3a/hadoop-aws:
      # - ./spark/jars:/opt/spark/jars
    networks: [lake]

  go-watcher:
    build: ./go
    depends_on: [minio]
    environment:
      - MINIO_ENDPOINT=http://minio:9000
      - MINIO_ACCESS_KEY=minio
      - MINIO_SECRET_KEY=minio12345
      - MINIO_BUCKET=mobility-delta
      - WATCH_PREFIX=bronze/trips
      - SLACK_WEBHOOK_URL=
    ports: ["9108:9108"]
    networks: [lake]

  rust-trip-sim:
    build: ./rust/trip_sim
    depends_on: [kafka]
    environment:
      - KAFKA_BROKER=kafka:9092
      - TOPIC=trips_raw
      - MSG_PER_SEC=10
    networks: [lake]

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports: ["9090:9090"]
    networks: [lake]

  grafana:
    image: grafana/grafana:10.4.2
    ports: ["3000:3000"]
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    networks: [lake]

  ui:
    build: ./ui
    depends_on: [trino]
    ports: ["5173:5173"]
    environment:
      - TRINO_HOST=trino
      - TRINO_PORT=8080
    networks: [lake]

  dbt-run:
    image: local/dbt-trino:1.8
    pull_policy: never
    depends_on: [trino]
    volumes:
      - ./dbt:/usr/app
    working_dir: /usr/app/mobility
    environment:
      - DBT_PROFILES_DIR=/usr/app
    networks: [lake]


  great-exp:
    image: python:3.11-slim
    working_dir: /app
    volumes:
      - ./airflow/great_expectations:/app/great_expectations
    command: bash -lc "pip install great_expectations==0.18.14 && bash"
    networks: [lake]

volumes:
  minio-data:
  airflow-logs:
  pg-data:

networks:
  lake:
    driver: bridge
